{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOS7wmkdT6juizGelJGjteB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# COLAB CELL 1: SETUP AND INITIALIZATION (FIXED)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# 1. Force reinstall a compatible version of Pillow (e.g., 9.5.0)\n",
        "# This resolves the conflict that caused the '_Ink' ImportError.\n",
        "!pip install -q Pillow==9.5.0\n",
        "\n",
        "# 2. Reinstall other packages to ensure dependencies are fully resolved\n",
        "# Use '-U --no-deps' for the second pass to avoid breaking Pillow again,\n",
        "# but ensure the core libraries are present.\n",
        "!pip install -q -U google-genai ultralytics opencv-python\n",
        "\n",
        "# Import the necessary libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "import datetime\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image # Should now import correctly\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "print(\"Pillow version fixed and models initialized.\")\n",
        "\n",
        "# --- USER CONFIGURATION and GLOBAL SETUP (Paste your original configuration here) ---\n",
        "\n",
        "# 1. Video File Path (MUST MATCH the filename in your Colab files list)\n",
        "VIDEO_FILE_PATH = \"/content/02.mp4\"\n",
        "\n",
        "# 2. PASTE YOUR VALID GEMINI API KEY HERE\n",
        "GEMINI_API_KEY = \"<your api key>\"\n",
        "\n",
        "# --- HEURISTIC TUNING (Copy-paste your variables here) ---\n",
        "FALL_THRESHOLD_Y = 0.75\n",
        "MIN_HEIGHT_RATIO = 1.0\n",
        "CRITICAL_WINDOW_SIZE = 8\n",
        "ROUTINE_INTERVAL = 5\n",
        "\n",
        "# --- GLOBAL SETUP ---\n",
        "try:\n",
        "    client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    pose_model = YOLO('yolov8n-pose.pt')\n",
        "\n",
        "    # Directory setup\n",
        "    OUTPUT_DIR = \"vlm_output_log\"\n",
        "    VLM_FRAMES_DIR = os.path.join(OUTPUT_DIR, \"frames\")\n",
        "    os.makedirs(VLM_FRAMES_DIR, exist_ok=True)\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    print(\"‚úÖ All Models and Client Initialized. Ready for Cell 2.\")\n",
        "except Exception as e:\n",
        "    print(f\"üö® Initialization Error: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "Q8mFSLhdr1UW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba757e5-201b-4c1e-eda3-085d98af04a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pillow version fixed and models initialized.\n",
            "‚úÖ All Models and Client Initialized. Ready for Cell 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# COLAB CELL 2: DETECTION, FILTERING, AND EXTRACTION FUNCTIONS\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def analyze_video_for_events(video_path):\n",
        "    \"\"\"Scans video using YOLOv8-Pose and heuristic logic to find critical and routine timestamps.\"\"\"\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        # This will only happen if the video file is missing or corrupted\n",
        "        raise FileNotFoundError(f\"Cannot open video file at {video_path}\")\n",
        "\n",
        "    critical_events_log = []\n",
        "    routine_timestamps = set()\n",
        "    last_routine_time = -1\n",
        "\n",
        "    print(\"\\n--- 1. Starting YOLOv8 Event Detection (GPU Scan) ---\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        current_time_s = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
        "\n",
        "        # --- CRITICAL EVENT (FALL) DETECTION LOGIC ---\n",
        "        results = pose_model(frame, verbose=False, classes=0) # Only detect people\n",
        "\n",
        "        if results and len(results[0].boxes) > 0:\n",
        "            keypoints = results[0].keypoints.xyn\n",
        "\n",
        "            if len(keypoints[0]) >= 13: # Ensure sufficient keypoints for hip calculation\n",
        "                hip_y = np.mean(keypoints[0][[11, 12], 1].cpu().numpy())\n",
        "                box = results[0].boxes[0].xyxy[0].cpu().numpy()\n",
        "                h_w_ratio = (box[3] - box[1]) / (box[2] - box[0])\n",
        "\n",
        "                # Heuristic Check: Low Hip AND Horizontal Posture\n",
        "                if hip_y > FALL_THRESHOLD_Y and h_w_ratio < MIN_HEIGHT_RATIO:\n",
        "                    critical_events_log.append(current_time_s)\n",
        "\n",
        "        # --- ROUTINE ACTIVITY SAMPLING ---\n",
        "        if current_time_s - last_routine_time >= ROUTINE_INTERVAL:\n",
        "            routine_timestamps.add(current_time_s)\n",
        "            last_routine_time = current_time_s\n",
        "\n",
        "        # Optimization: Process every 0.2 seconds to speed up scan\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, (current_time_s + 0.2) * 1000)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # --- Final Window Calculation ---\n",
        "    critical_timestamps = set()\n",
        "    if critical_events_log:\n",
        "        first_detection = min(critical_events_log)\n",
        "        last_detection = max(critical_events_log)\n",
        "\n",
        "        start_time = max(0, first_detection - CRITICAL_WINDOW_SIZE / 2)\n",
        "        end_time = last_detection + CRITICAL_WINDOW_SIZE / 2\n",
        "\n",
        "        # Convert window to 1-second timestamps\n",
        "        for t in range(int(start_time), int(end_time) + 1, 1):\n",
        "            critical_timestamps.add(t)\n",
        "\n",
        "        print(f\"‚úÖ Fall Incident Window Identified: [{start_time:.2f}s - {end_time:.2f}s]\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No Critical Incidents Detected. Routine log only.\")\n",
        "\n",
        "    all_vlm_timestamps = sorted(list(routine_timestamps.union(critical_timestamps)))\n",
        "    print(f\"Total Frames Filtered for VLM Analysis: {len(all_vlm_timestamps)}\")\n",
        "\n",
        "    return all_vlm_timestamps, critical_timestamps\n",
        "\n",
        "\n",
        "def extract_keyframes(video_path, timestamps):\n",
        "    \"\"\"Extracts frames only at specified timestamps and saves them to disk.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    extracted_files = []\n",
        "\n",
        "    for t_sec in timestamps:\n",
        "        cap.set(cv2.CAP_PROP_POS_MSEC, t_sec * 1000)\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret:\n",
        "            # Use fixed naming convention for later VLM processing\n",
        "            filename = os.path.join(VLM_FRAMES_DIR, f\"frame_{t_sec:.2f}s.jpg\")\n",
        "            cv2.imwrite(filename, frame)\n",
        "            extracted_files.append((t_sec, filename))\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"‚úÖ Extracted {len(extracted_files)} keyframes to '{VLM_FRAMES_DIR}'.\")\n",
        "    return extracted_files"
      ],
      "metadata": {
        "id": "mMDjgOcnr4a0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# COLAB CELL 3: VLM CAPTIONING AND FINAL FUSION FUNCTIONS\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def generate_vlm_captions(extracted_frames, critical_timestamps):\n",
        "    \"\"\"Sends filtered keyframes to Gemini VLM for description and stores the log.\"\"\"\n",
        "    MODEL_NAME = \"gemini-2.5-flash\"\n",
        "    VISUAL_LOG_DATA = []\n",
        "\n",
        "    print(\"\\n--- 2. Starting VLM Caption Generation (API Calls) ---\")\n",
        "\n",
        "    for t_sec, frame_path in extracted_frames:\n",
        "        try:\n",
        "            img = Image.open(frame_path)\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "            # ----------------------------------------------------\n",
        "\n",
        "            is_critical = int(t_sec) in critical_timestamps\n",
        "            log_type = 'CRITICAL' if is_critical else 'ROUTINE'\n",
        "\n",
        "            if is_critical:\n",
        "                prompt_text = (\n",
        "                    f\"TIME {t_sec:.2f}s (CRITICAL INCIDENT): You are a forensic analyst. \"\n",
        "                    \"Detail the patient's exact posture, direction, and position relative to the bed/floor. \"\n",
        "                    \"Strictly report on activity and objects only.\"\n",
        "                )\n",
        "            else:\n",
        "                prompt_text = (\n",
        "                    f\"TIME {t_sec:.2f}s (ROUTINE CHECK): Describe the patient's primary status (sleeping/sitting/resting) and \"\n",
        "                    \"the overall room environment in one concise, objective sentence.\"\n",
        "                )\n",
        "\n",
        "            response = client.models.generate_content(\n",
        "                model=MODEL_NAME,\n",
        "                contents=[prompt_text, img],\n",
        "                config=types.GenerateContentConfig(temperature=0.2)\n",
        "            )\n",
        "\n",
        "            VISUAL_LOG_DATA.append({\n",
        "                'timestamp': t_sec,\n",
        "                'type': log_type,\n",
        "                'description': response.text.strip()\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"üö® Error processing VLM frame at {t_sec:.2f}s: {e}\")\n",
        "\n",
        "    return VISUAL_LOG_DATA\n",
        "\n",
        "\n",
        "def generate_final_report(visual_log):\n",
        "    \"\"\"Formats the visual log into the final archival report using the LLM.\"\"\"\n",
        "\n",
        "    visual_text = \"\\n\".join([f\"[{item['timestamp']:.2f}s, {item['type']}]: {item['description']}\" for item in visual_log])\n",
        "\n",
        "    full_prompt = (\n",
        "        \"You are a Geriatric Incident Analyst. Your task is to generate a formal, structured daily archival log \"\n",
        "        \"based *only* on the visual event log provided below. The goal is to provide a comprehensive summary \"\n",
        "        \"for medical auditing. \\n\\n\"\n",
        "        \"**Strict Output Format (Use only these two markdown headers):**\\n\"\n",
        "        \"1. ## CRITICAL INCIDENT REPORT ##: Generate a detailed narrative for all events marked 'CRITICAL'. Stitch sequential visual observations into a continuous, minute-by-minute account.\\n\"\n",
        "        \"2. ## ROUTINE ACTIVITY LOG ##: Generate a chronological log of all routine activity. Group continuous, long periods of activity (like sleeping) into single, time-block paragraphs.\\n\\n\"\n",
        "        \"--- VISUAL EVENT LOG ---\\n\"\n",
        "        f\"{visual_text}\\n\"\n",
        "        \"--- END DATA ---\"\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- 3. Starting Final Report Generation (LLM Reasoning) ---\")\n",
        "    report_response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=full_prompt,\n",
        "        config=types.GenerateContentConfig(temperature=0.1)\n",
        "    )\n",
        "\n",
        "    return report_response.text.strip()"
      ],
      "metadata": {
        "id": "Dm-9jQI3r87W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------\n",
        "# COLAB CELL 4: MAIN EXECUTION BLOCK\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    \"\"\"Runs the entire vision pipeline.\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 1. Detection and Sampling\n",
        "    all_vlm_timestamps, critical_timestamps = analyze_video_for_events(VIDEO_FILE_PATH)\n",
        "\n",
        "    if not all_vlm_timestamps:\n",
        "        print(\"üõë PROCESS HALTED: No frames were selected for analysis.\")\n",
        "        return\n",
        "\n",
        "    # 2. Keyframe Extraction\n",
        "    extracted_frames = extract_keyframes(VIDEO_FILE_PATH, all_vlm_timestamps)\n",
        "\n",
        "    # 3. VLM Captioning\n",
        "    visual_log_data = generate_vlm_captions(extracted_frames, critical_timestamps)\n",
        "\n",
        "    # 4. Save intermediate JSON log (Optional but useful for debugging)\n",
        "    LOG_FILENAME_FINAL = os.path.join(OUTPUT_DIR, \"visual_log_intermediate.json\")\n",
        "    with open(LOG_FILENAME_FINAL, 'w') as f:\n",
        "        json.dump(visual_log_data, f, indent=4)\n",
        "\n",
        "    # 5. Final Report Generation (Fusion)\n",
        "    final_report_text = generate_final_report(visual_log_data)\n",
        "\n",
        "    # 6. Display and Save Final Output\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"             FINAL VISION-ONLY DAILY ARCHIVAL LOG\")\n",
        "    print(\"=\" * 80)\n",
        "    # Print the synthesized report text\n",
        "    print(final_report_text)\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    archive_filename = \"Vision_Only_Archival_Log.txt\"\n",
        "    with open(archive_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(final_report_text)\n",
        "\n",
        "    # Download the file\n",
        "    from google.colab import files\n",
        "    files.download(archive_filename)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"\\n‚úÖ PROJECT SUCCESS. Total Runtime: {(end_time - start_time):.2f} seconds.\")\n",
        "\n",
        "\n",
        "# --- ACTIVATE THE PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rKWUp-pssfct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "6b705148-3444-4ed0-d370-4e642c76fa18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Starting YOLOv8 Event Detection (GPU Scan) ---\n",
            "‚úÖ Fall Incident Window Identified: [0.00s - 12.24s]\n",
            "Total Frames Filtered for VLM Analysis: 14\n",
            "‚úÖ Extracted 10 keyframes to 'vlm_output_log/frames'.\n",
            "\n",
            "--- 2. Starting VLM Caption Generation (API Calls) ---\n",
            "\n",
            "--- 3. Starting Final Report Generation (LLM Reasoning) ---\n",
            "\n",
            "================================================================================\n",
            "             FINAL VISION-ONLY DAILY ARCHIVAL LOG\n",
            "================================================================================\n",
            "## CRITICAL INCIDENT REPORT ##\n",
            "\n",
            "At **0.00s**, the patient was observed standing upright on a red and white checkered rug. Their head and upper torso were slightly inclined forward, with both arms positioned downwards, the left arm exhibiting a slight bend at the elbow. The patient was facing towards the right side of the image, generally oriented towards the bed and the window beyond it, appearing to be in a standing or paused walking stance. They were positioned to the left of the bed, not in direct physical contact with it. The patient was wearing a light brown/khaki short-sleeved t-shirt and dark blue/black trousers.\n",
            "\n",
            "By **1.00s**, the patient remained standing upright on the red and white checkered rug, approximately 1 to 2 feet away from the side of the bed. Their head was slightly bowed with gaze directed downwards, and arms were positioned at their sides. Their left leg was forward and the right leg positioned behind, indicating a walking or mid-stride stance. The patient's torso and head were oriented towards the right side of the image frame, appearing to move or face generally towards the right side of the room.\n",
            "\n",
            "At **2.00s**, the patient was standing still, erect on the red and white checkered mat, positioned in the foreground approximately 1.5 to 2 meters away from the bed, which was situated behind and to the patient's left. Their head was tilted downwards, with their gaze directed towards the floor in front of them. Both arms hung loosely at their sides. The patient's torso was oriented generally towards the viewer, with a slight angle to the viewer's right, and their head turned slightly to the viewer's left and downwards.\n",
            "\n",
            "At **3.00s**, a significant change in the patient's posture was observed. While still standing upright on the red and white checkered mat, their torso was bent forward at the waist, approximately 45 degrees from vertical. Their head was angled downwards, looking towards the floor. The patient was actively reaching downwards towards the floor with their right hand, which had fingers slightly splayed. Their left arm was bent at the elbow, with the hand positioned near the left hip. Their legs remained mostly straight. The patient's body was oriented with their front facing generally towards the right side of the frame, and their head directed towards the floor in front of them, approximately 1-2 feet away from the bed.\n",
            "\n",
            "By **4.00s**, the patient was observed lying on the floor on the red and white checkered mat, in a prone or semi-prone recumbent position. Their head was turned to the viewer's left, resting on their left arm, which was bent at the elbow. Their right arm was extended forward and bent at the elbow. Both legs were bent at the knees. The patient's head was oriented towards the viewer's left, and their body generally oriented with the head towards the viewer's left and feet towards the viewer's right.\n",
            "\n",
            "A few moments later, at **4.03s**, the patient was lying prone (face down) on the floor, with their torso flat against the floor on the red and white checkered mat. Their left arm was bent at the elbow, with the forearm and hand extended forward. Their right arm was bent, with the forearm and hand positioned near their head/chest. Their legs were bent at the knees, with their lower legs and feet extending towards the left side of the frame. The patient's head was oriented towards the right side of the image, facing the floor/mat, and their feet were oriented towards the left. The patient was approximately 2-3 feet away from the side of the bed and appeared to be in a state of rest or lying down, with no active movement discernible.\n",
            "\n",
            "At **5.00s**, the patient remained lying motionless on the red and white checkered mat, primarily on their abdomen/chest. Their head was turned to their right (viewer's right), facing generally towards the floral-patterned door. Their right arm was extended forward, bent at the elbow, with the hand near their head. Their left arm was bent, with the hand near their chest/shoulder. Both legs were bent at the knees. Their feet were oriented towards the left side of the room (towards the clothes rack). The patient was wearing a light-colored (tan/brown) short-sleeved top and dark-colored long pants.\n",
            "\n",
            "By **6.00s**, the patient had shifted to lying on their right side on the red and white checkered mat/rug. Their legs were bent at the knees, with the left leg positioned slightly forward of the right. Their right arm appeared extended forward. Their head was oriented towards the right side of the image (towards the floral-patterned door), and their feet were oriented towards the left side of the image (towards the clothes rack). No active movement was observed. The patient was noted to be wearing dark trousers/pants and a light brown/tan long-sleeved shirt.\n",
            "\n",
            "At **7.00s**, the patient continued to lie on the floor on their right side on the red and white checkered mat. Their torso was oriented mostly flat against the floor, with a slight rotation. Their head was turned to their left (towards the clothes rack and left window). Both knees were bent, with the right knee acutely bent and the right foot positioned near the left knee. Their right arm was bent at the elbow, with the hand located near the head; the left arm was not visible. Their feet were oriented towards the right side of the room (towards the door). Their head was approximately level with the foot of the bed, and their body was situated roughly parallel to the bed with a discernible space between them and the bed frame. No discernible activity was observed.\n",
            "\n",
            "Finally, at **8.00s**, the patient was still lying on their right side on the floor, on the mat in the foreground, approximately 1-2 meters from the bed. Their torso was relatively straight, and both legs were bent at the knees, with the left leg positioned slightly over the right. Their head was turned to the left, oriented towards the wall with hanging clothes, and their feet were oriented towards the right side of the room, towards the door. No discernible activity was observed. The patient was wearing a light-colored shirt and dark pants.\n",
            "\n",
            "## ROUTINE ACTIVITY LOG ##\n",
            "No routine activity was observed during the monitored period. All recorded events were classified as critical incidents.\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4a031ad-a8ab-489d-ac8f-1ea302ccaac9\", \"Vision_Only_Archival_Log.txt\", 6285)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ PROJECT SUCCESS. Total Runtime: 189.56 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ot-2ItPFspX7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}